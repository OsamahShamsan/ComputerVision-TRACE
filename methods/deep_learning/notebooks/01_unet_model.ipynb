{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/osamahshamsan/Desktop/Master/CV/TRACE\n",
      "Method root: /Users/osamahshamsan/Desktop/Master/CV/TRACE/methods/deep_learning\n",
      "PyTorch version: 2.8.0\n",
      "CUDA available: False\n",
      "MPS (Apple Silicon) available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add src directory to path\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    " project_root = current_dir.parent.parent.parent\n",
    " method_root = current_dir.parent\n",
    "else:\n",
    " project_root = Path.cwd()\n",
    " method_root = project_root / 'methods' / 'deep_learning'\n",
    "\n",
    "sys.path.append(str(method_root / 'src'))\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import get_data_loaders\n",
    "from model1_unet import create_unet_model\n",
    "from trainer import ModelTrainer\n",
    "from evaluator import ModelEvaluator\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Method root: {method_root}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# Check for MPS (Apple Silicon GPU)\n",
    "if hasattr(torch.backends, 'mps'):\n",
    " print(f\"MPS (Apple Silicon) available: {torch.backends.mps.is_available()}\")\n",
    "else:\n",
    " print(\"MPS not available in this PyTorch version\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataset files...\n",
      "============================================================\n",
      "\n",
      "Dataset sizes after validation:\n",
      " Train: 5858 pairs\n",
      " Validation: 1256 pairs\n",
      " Test: 1256 pairs\n",
      "\n",
      "All training files are valid!\n",
      "\n",
      "Found checkpoint from epoch 10\n",
      " Training will automatically resume from epoch 11\n",
      " Best validation loss so far: 0.6896\n",
      " Best validation IoU so far: 0.2811\n"
     ]
    }
   ],
   "source": [
    "# Check for corrupted files and verify dataset integrity\n",
    "print(\"Validating dataset files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load config if not already loaded (in case this cell is run before the config cell)\n",
    "if 'config' not in globals():\n",
    "    config_path = method_root / 'configs' / 'dl_config.json'\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    # Resolve data paths relative to project root\n",
    "    for key in config['data_paths']:\n",
    "        path = config['data_paths'][key]\n",
    "        if not Path(path).is_absolute():\n",
    "            levels_up = path.count('../')\n",
    "            if levels_up > 0:\n",
    "                actual_path = '/'.join(path.split('/')[levels_up:])\n",
    "                config['data_paths'][key] = str(project_root / actual_path)\n",
    "            else:\n",
    "                config['data_paths'][key] = str(project_root / path)\n",
    "\n",
    "# Recreate data loaders to see if any files are corrupted\n",
    "# The data loader will now automatically skip corrupted files\n",
    "train_loader, val_loader, test_loader = get_data_loaders(config)\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"\\nDataset sizes after validation:\")\n",
    "print(f\" Train: {len(train_loader.dataset)} pairs\")\n",
    "print(f\" Validation: {len(val_loader.dataset)} pairs\")\n",
    "print(f\" Test: {len(test_loader.dataset)} pairs\")\n",
    "\n",
    "# Check if there were any corrupted files\n",
    "if hasattr(train_loader.dataset, 'corrupted_files') and train_loader.dataset.corrupted_files:\n",
    " print(f\"\\nFound {len(train_loader.dataset.corrupted_files)} corrupted file pairs in training set\")\n",
    " print(\"These files will be skipped during training.\")\n",
    "else:\n",
    " print(\"\\nAll training files are valid!\")\n",
    "\n",
    "# Check for existing checkpoints\n",
    "# Check both possible locations (notebooks/outputs and method_root/outputs)\n",
    "checkpoint_latest = method_root / 'outputs' / 'models' / 'unet_model1_latest.pth'\n",
    "checkpoint_best = method_root / 'outputs' / 'models' / 'unet_model1_best.pth'\n",
    "\n",
    "# Also check in notebooks directory (where checkpoints might have been saved)\n",
    "notebooks_checkpoint = method_root / 'notebooks' / 'outputs' / 'models' / 'unet_model1_latest.pth'\n",
    "if not checkpoint_latest.exists() and notebooks_checkpoint.exists():\n",
    "    checkpoint_latest = notebooks_checkpoint\n",
    "    checkpoint_best = method_root / 'notebooks' / 'outputs' / 'models' / 'unet_model1_best.pth'\n",
    "\n",
    "if checkpoint_latest.exists():\n",
    " # Use device if available, otherwise use 'cpu' for checkpoint loading\n",
    " # (device will be defined in the Setup Device cell)\n",
    " checkpoint_device = device if 'device' in globals() else 'cpu'\n",
    " checkpoint = torch.load(checkpoint_latest, map_location=checkpoint_device)\n",
    " print(f\"\\nFound checkpoint from epoch {checkpoint['epoch']}\")\n",
    " print(f\" Training will automatically resume from epoch {checkpoint['epoch'] + 1}\")\n",
    " print(f\" Best validation loss so far: {checkpoint['best_val_loss']:.4f}\")\n",
    " print(f\" Best validation IoU so far: {checkpoint['best_val_iou']:.4f}\")\n",
    "else:\n",
    " print(\"\\nNo checkpoint found - training will start from epoch 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "{\n",
      "  \"model_settings\": {\n",
      "    \"image_size\": [\n",
      "      512,\n",
      "      512\n",
      "    ],\n",
      "    \"num_channels\": 3,\n",
      "    \"num_classes\": 2,\n",
      "    \"batch_size\": 8,\n",
      "    \"learning_rate\": 0.0001,\n",
      "    \"num_epochs\": 50,\n",
      "    \"device\": \"cuda\"\n",
      "  },\n",
      "  \"model1_unet\": {\n",
      "    \"name\": \"U-Net Segmentation Model\",\n",
      "    \"encoder\": \"resnet34\",\n",
      "    \"encoder_weights\": \"imagenet\",\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"loss\": \"bce_with_logits\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"save_best_only\": true,\n",
      "    \"patience\": 5\n",
      "  },\n",
      "  \"model2_resnet\": {\n",
      "    \"name\": \"ResNet Encoder-Decoder Model\",\n",
      "    \"backbone\": \"resnet50\",\n",
      "    \"backbone_weights\": \"imagenet\",\n",
      "    \"decoder_channels\": [\n",
      "      256,\n",
      "      128,\n",
      "      64,\n",
      "      32,\n",
      "      16\n",
      "    ],\n",
      "    \"activation\": \"sigmoid\",\n",
      "    \"loss\": \"dice\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"save_best_only\": true,\n",
      "    \"patience\": 5\n",
      "  },\n",
      "  \"data_paths\": {\n",
      "    \"train_images\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/train/images\",\n",
      "    \"train_masks\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/train/masks\",\n",
      "    \"val_images\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/val/images\",\n",
      "    \"val_masks\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/val/masks\",\n",
      "    \"test_images\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/test/images\",\n",
      "    \"test_masks\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/data/processed/test/masks\"\n",
      "  },\n",
      "  \"output_paths\": {\n",
      "    \"models\": \"outputs/models\",\n",
      "    \"predictions\": \"outputs/predictions\",\n",
      "    \"visualizations\": \"outputs/visualizations\",\n",
      "    \"logs\": \"outputs/logs\"\n",
      "  },\n",
      "  \"results_paths\": {\n",
      "    \"metrics\": \"results/metrics\",\n",
      "    \"comparisons\": \"results/comparisons\"\n",
      "  },\n",
      "  \"augmentation\": {\n",
      "    \"enabled\": true,\n",
      "    \"rotation_range\": 15,\n",
      "    \"horizontal_flip\": true,\n",
      "    \"vertical_flip\": false,\n",
      "    \"brightness_range\": [\n",
      "      0.8,\n",
      "      1.2\n",
      "    ],\n",
      "    \"contrast_range\": [\n",
      "      0.8,\n",
      "      1.2\n",
      "    ],\n",
      "    \"gaussian_noise\": 0.01\n",
      "  },\n",
      "  \"evaluation\": {\n",
      "    \"metrics\": [\n",
      "      \"iou\",\n",
      "      \"dice\",\n",
      "      \"precision\",\n",
      "      \"recall\",\n",
      "      \"f1\"\n",
      "    ],\n",
      "    \"save_predictions\": true,\n",
      "    \"num_visualizations\": 20\n",
      "  },\n",
      "  \"method_root\": \"/Users/osamahshamsan/Desktop/Master/CV/TRACE/methods/deep_learning\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = method_root / 'configs' / 'dl_config.json'\n",
    "with open(config_path, 'r') as f:\n",
    " config = json.load(f)\n",
    "\n",
    "# Resolve data paths relative to project root (fix relative path issues)\n",
    "# Config paths are like \"../../../data/processed/...\" - need to extract actual path\n",
    "for key in config['data_paths']:\n",
    " path = config['data_paths'][key]\n",
    " if not Path(path).is_absolute():\n",
    "  # Count ../ levels and extract actual path\n",
    "  levels_up = path.count('../')\n",
    "  if levels_up > 0:\n",
    "   # Remove ../ parts and get the actual path (e.g., \"data/processed/train/images\")\n",
    "   actual_path = '/'.join(path.split('/')[levels_up:])\n",
    "   config['data_paths'][key] = str(project_root / actual_path)\n",
    "  else:\n",
    "   config['data_paths'][key] = str(project_root / path)\n",
    "\n",
    "# Add method_root to config so trainer can resolve output paths correctly\n",
    "config['method_root'] = str(method_root)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(json.dumps(config, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Device and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon GPU)\n",
      "Using device: mps\n",
      "\n",
      "Verifying data paths:\n",
      " train: Images=5858 (), Masks=5858 ()\n",
      " val: Images=1256 (), Masks=1256 ()\n",
      " test: Images=1256 (), Masks=1256 ()\n",
      "\n",
      "Loading datasets...\n",
      "\n",
      "Data loaders created:\n",
      " Train batches: 733\n",
      " Validation batches: 157\n",
      " Test batches: 157\n",
      "\n",
      "Sample batch shape:\n",
      " Images: torch.Size([8, 3, 512, 512])\n",
      " Masks: torch.Size([8, 1, 512, 512])\n",
      " Image value range: [0.000, 1.000]\n",
      " Mask value range: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "# Setup device - check for CUDA, MPS (Apple Silicon), or CPU\n",
    "if torch.cuda.is_available() and config['model_settings']['device'] == 'cuda':\n",
    " device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    " device = torch.device('mps')\n",
    " print(\"Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    " device = torch.device('cpu')\n",
    " print(\"Using CPU (no GPU acceleration available)\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Verify data paths exist\n",
    "print(\"\\nVerifying data paths:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    " img_path = Path(config['data_paths'][f'{split}_images'])\n",
    " mask_path = Path(config['data_paths'][f'{split}_masks'])\n",
    " img_exists = img_path.exists()\n",
    " mask_exists = mask_path.exists()\n",
    " img_count = len(list(img_path.glob('*.png'))) if img_exists else 0\n",
    " mask_count = len(list(mask_path.glob('*.png'))) if mask_exists else 0\n",
    " print(f\" {split}: Images={img_count} ({'' if img_exists else ''}), Masks={mask_count} ({'' if mask_exists else ''})\")\n",
    "\n",
    "# Create data loaders\n",
    "print(\"\\nLoading datasets...\")\n",
    "train_loader, val_loader, test_loader = get_data_loaders(config)\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\" Train batches: {len(train_loader)}\")\n",
    "print(f\" Validation batches: {len(val_loader)}\")\n",
    "print(f\" Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Check a sample batch\n",
    "sample_images, sample_masks = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shape:\")\n",
    "print(f\" Images: {sample_images.shape}\")\n",
    "print(f\" Masks: {sample_masks.shape}\")\n",
    "print(f\" Image value range: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
    "print(f\" Mask value range: [{sample_masks.min():.3f}, {sample_masks.max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create U-Net Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: U-Net Segmentation Model\n",
      "Encoder: resnet34\n",
      "Total parameters: 24,522,785\n",
      "Trainable parameters: 24,522,785\n",
      "\n",
      "Test forward pass:\n",
      " Input shape: torch.Size([2, 3, 512, 512])\n",
      " Output shape: torch.Size([2, 1, 512, 512])\n",
      " Expected output: [batch, 1, 512, 512]\n",
      " Output shape is correct!\n"
     ]
    }
   ],
   "source": [
    "# Reload module to pick up any code changes\n",
    "import importlib\n",
    "import model1_unet\n",
    "importlib.reload(model1_unet)\n",
    "from model1_unet import create_unet_model\n",
    "\n",
    "# Create U-Net model\n",
    "model = create_unet_model(config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: {config['model1_unet']['name']}\")\n",
    "print(f\"Encoder: {config['model1_unet']['encoder']}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    " test_output = model(sample_images[:2].to(device))\n",
    " print(f\"\\nTest forward pass:\")\n",
    " print(f\" Input shape: {sample_images[:2].shape}\")\n",
    " print(f\" Output shape: {test_output.shape}\")\n",
    " print(f\" Expected output: [batch, 1, 512, 512]\")\n",
    " if test_output.shape[1] == 1 and test_output.shape[2] == 512 and test_output.shape[3] == 512:\n",
    "  print(\" Output shape is correct!\")\n",
    " else:\n",
    "  print(f\" Output shape mismatch! Expected [batch, 1, 512, 512]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from outputs/models/unet_model1_latest.pth\n",
      "Resuming from epoch 10\n",
      "Best validation loss so far: 0.6896\n",
      "Best validation IoU so far: 0.2811\n",
      "Starting training for unet_model1\n",
      "Device: mps\n",
      "Number of epochs: 50\n",
      "Starting from epoch: 11\n",
      "------------------------------------------------------------\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.6890, Train IoU: 0.3275\n",
      "  Val Loss: 0.6893, Val IoU: 0.2962\n",
      "Saved best model at epoch 11 with val_loss=0.6893, val_iou=0.2962\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.6888, Train IoU: 0.3368\n",
      "  Val Loss: 0.6893, Val IoU: 0.2804\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.6887, Train IoU: 0.3306\n",
      "  Val Loss: 0.6889, Val IoU: 0.3027\n",
      "Saved best model at epoch 13 with val_loss=0.6889, val_iou=0.3027\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.6885, Train IoU: 0.3426\n",
      "  Val Loss: 0.6889, Val IoU: 0.3031\n",
      "Saved best model at epoch 14 with val_loss=0.6889, val_iou=0.3031\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.6886, Train IoU: 0.3291\n",
      "  Val Loss: 0.6890, Val IoU: 0.2909\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.6886, Train IoU: 0.3366\n",
      "  Val Loss: 0.6888, Val IoU: 0.3054\n",
      "Saved best model at epoch 16 with val_loss=0.6888, val_iou=0.3054\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.6884, Train IoU: 0.3424\n",
      "  Val Loss: 0.6888, Val IoU: 0.3062\n",
      "Saved best model at epoch 17 with val_loss=0.6888, val_iou=0.3062\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.6883, Train IoU: 0.3429\n",
      "  Val Loss: 0.6888, Val IoU: 0.3003\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.6884, Train IoU: 0.3396\n",
      "  Val Loss: 0.6888, Val IoU: 0.3065\n",
      "Saved best model at epoch 19 with val_loss=0.6888, val_iou=0.3065\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.6883, Train IoU: 0.3429\n",
      "  Val Loss: 0.6887, Val IoU: 0.2986\n",
      "Saved best model at epoch 20 with val_loss=0.6887, val_iou=0.2986\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.6883, Train IoU: 0.3536\n",
      "  Val Loss: 0.6888, Val IoU: 0.2908\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.6884, Train IoU: 0.3449\n",
      "  Val Loss: 0.6889, Val IoU: 0.2881\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.6883, Train IoU: 0.3422\n",
      "  Val Loss: 0.6888, Val IoU: 0.2984\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3490\n",
      "  Val Loss: 0.6887, Val IoU: 0.2990\n",
      "Saved best model at epoch 24 with val_loss=0.6887, val_iou=0.2990\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3490\n",
      "  Val Loss: 0.6887, Val IoU: 0.3069\n",
      "Saved best model at epoch 25 with val_loss=0.6887, val_iou=0.3069\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.6883, Train IoU: 0.3545\n",
      "  Val Loss: 0.6887, Val IoU: 0.3071\n",
      "Saved best model at epoch 26 with val_loss=0.6887, val_iou=0.3071\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3551\n",
      "  Val Loss: 0.6887, Val IoU: 0.3091\n",
      "Saved best model at epoch 27 with val_loss=0.6887, val_iou=0.3091\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3527\n",
      "  Val Loss: 0.6887, Val IoU: 0.3055\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.6881, Train IoU: 0.3603\n",
      "  Val Loss: 0.6888, Val IoU: 0.3091\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3504\n",
      "  Val Loss: 0.6886, Val IoU: 0.3117\n",
      "Saved best model at epoch 30 with val_loss=0.6886, val_iou=0.3117\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.6880, Train IoU: 0.3635\n",
      "  Val Loss: 0.6887, Val IoU: 0.3098\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.6882, Train IoU: 0.3541\n",
      "  Val Loss: 0.6888, Val IoU: 0.3062\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.6881, Train IoU: 0.3602\n",
      "  Val Loss: 0.6888, Val IoU: 0.3107\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.6881, Train IoU: 0.3643\n",
      "  Val Loss: 0.6887, Val IoU: 0.3106\n",
      "Epoch 35/50\n",
      "  Train Loss: 0.6881, Train IoU: 0.3643\n",
      "  Val Loss: 0.6886, Val IoU: 0.3093\n",
      "Saved best model at epoch 35 with val_loss=0.6886, val_iou=0.3093\n",
      "Epoch 36/50\n",
      "  Train Loss: 0.6881, Train IoU: 0.3563\n",
      "  Val Loss: 0.6886, Val IoU: 0.3078\n",
      "Epoch 37/50\n",
      "  Train Loss: 0.6880, Train IoU: 0.3569\n",
      "  Val Loss: 0.6888, Val IoU: 0.2975\n",
      "Epoch 38/50\n",
      "  Train Loss: 0.6880, Train IoU: 0.3592\n",
      "  Val Loss: 0.6887, Val IoU: 0.3099\n",
      "Epoch 39/50\n",
      "  Train Loss: 0.6879, Train IoU: 0.3640\n",
      "  Val Loss: 0.6886, Val IoU: 0.3077\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = ModelTrainer(\n",
    " model=model,\n",
    " config=config,\n",
    " device=device,\n",
    " model_name='unet_model1'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "# resume_from_checkpoint=True will automatically resume from the latest checkpoint\n",
    "# Set to False if you want to start training from scratch\n",
    "num_epochs = config['model_settings']['num_epochs']\n",
    "trainer.train(\n",
    " train_loader=train_loader,\n",
    " val_loader=val_loader,\n",
    " num_epochs=num_epochs,\n",
    " resume_from_checkpoint=True # Automatically resume from latest checkpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_path = method_root / 'outputs' / 'models' / 'unet_model1_best.pth'\n",
    "if checkpoint_path.exists():\n",
    " checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    " model.load_state_dict(checkpoint['model_state_dict'])\n",
    " print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    " print(f\"Best validation loss: {checkpoint['best_val_loss']:.4f}\")\n",
    " print(f\"Best validation IoU: {checkpoint['best_val_iou']:.4f}\")\n",
    "else:\n",
    " print(\"Best model checkpoint not found, using current model state\")\n",
    "\n",
    "# Create evaluator\n",
    "output_dir = method_root / config['output_paths']['predictions']\n",
    "results_dir = method_root / config['results_paths']['metrics']\n",
    "\n",
    "evaluator = ModelEvaluator(\n",
    " model=model,\n",
    " device=device,\n",
    " output_dir=output_dir,\n",
    " results_dir=results_dir\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = evaluator.evaluate(\n",
    " test_loader=test_loader,\n",
    " save_predictions=config['evaluation']['save_predictions'],\n",
    " num_visualizations=config['evaluation']['num_visualizations']\n",
    ")\n",
    "\n",
    "# Print metrics\n",
    "evaluator.print_metrics(test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load training history\n",
    "history_path = method_root / 'outputs' / 'models' / 'unet_model1_history.json'\n",
    "if history_path.exists():\n",
    " with open(history_path, 'r') as f:\n",
    " history = json.load(f)\n",
    " \n",
    " # Plot training curves\n",
    " fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    " \n",
    " # Loss plot\n",
    " axes[0].plot(history['train_loss'], label='Train Loss')\n",
    " axes[0].plot(history['val_loss'], label='Validation Loss')\n",
    " axes[0].set_xlabel('Epoch')\n",
    " axes[0].set_ylabel('Loss')\n",
    " axes[0].set_title('Training and Validation Loss')\n",
    " axes[0].legend()\n",
    " axes[0].grid(True)\n",
    " \n",
    " # IoU plot\n",
    " axes[1].plot(history['train_iou'], label='Train IoU')\n",
    " axes[1].plot(history['val_iou'], label='Validation IoU')\n",
    " axes[1].set_xlabel('Epoch')\n",
    " axes[1].set_ylabel('IoU')\n",
    " axes[1].set_title('Training and Validation IoU')\n",
    " axes[1].legend()\n",
    " axes[1].grid(True)\n",
    " \n",
    " plt.tight_layout()\n",
    " plt.savefig(method_root / 'outputs' / 'visualizations' / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    " plt.show()\n",
    " \n",
    " print(f\"Training completed in {len(history['train_loss'])} epochs\")\n",
    "else:\n",
    " print(\"Training history not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "U-Net model training and evaluation completed. Results saved to:\n",
    "- **Models**: `outputs/models/`\n",
    "- **Predictions**: `outputs/predictions/`\n",
    "- **Visualizations**: `outputs/visualizations/`\n",
    "- **Metrics**: `results/metrics/`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "languageId": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
