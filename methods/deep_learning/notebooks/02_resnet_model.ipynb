{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ResNet Encoder-Decoder Model for Copy-Move Forgery Detection\n",
        "\n",
        "This notebook implements and trains a ResNet-based encoder-decoder model for detecting copy-move manipulated regions in images.\n",
        "\n",
        "## Model Architecture\n",
        "- **Encoder**: Pre-trained ResNet50 (ImageNet weights) - provides good feature extraction\n",
        "- **Decoder**: Custom decoder with transposed convolutions - randomly initialized, needs training\n",
        "- **Output**: Binary segmentation mask (1 channel)\n",
        "\n",
        "## Why Training is Needed\n",
        "Even though the encoder is pre-trained on ImageNet, we still need to train the entire model because:\n",
        "1. **Decoder is not pre-trained** - it's randomly initialized and needs to learn how to reconstruct masks\n",
        "2. **Task-specific adaptation** - the encoder needs to adapt from general object recognition to copy-move detection\n",
        "3. **End-to-end learning** - the encoder and decoder need to work together for this specific task\n",
        "\n",
        "**Pre-trained = Good starting point, not a finished model!**\n",
        "\n",
        "## Dataset\n",
        "- Uses processed data from `data/processed/` (already split into train/val/test 70/15/15)\n",
        "- Images are 512x512 RGB PNG files\n",
        "- Masks are binary segmentation masks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Add src directory to path\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == 'notebooks':\n",
        "    project_root = current_dir.parent.parent.parent\n",
        "    method_root = current_dir.parent\n",
        "else:\n",
        "    project_root = Path.cwd()\n",
        "    method_root = project_root / 'methods' / 'deep_learning'\n",
        "\n",
        "sys.path.append(str(method_root / 'src'))\n",
        "\n",
        "# Import custom modules\n",
        "from data_loader import get_data_loaders\n",
        "from model2_resnet import create_resnet_model\n",
        "from trainer import ModelTrainer\n",
        "from evaluator import ModelEvaluator\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Method root: {method_root}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "# Check for MPS (Apple Silicon GPU)\n",
        "if hasattr(torch.backends, 'mps'):\n",
        "    print(f\"MPS (Apple Silicon) available: {torch.backends.mps.is_available()}\")\n",
        "else:\n",
        "    print(\"MPS not available in this PyTorch version\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config_path = method_root / 'configs' / 'dl_config.json'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Resolve data paths relative to project root (fix relative path issues)\n",
        "# Config paths are like \"../../../data/processed/...\" - need to extract actual path\n",
        "for key in config['data_paths']:\n",
        "    path = config['data_paths'][key]\n",
        "    if not Path(path).is_absolute():\n",
        "        # Count ../ levels and extract actual path\n",
        "        levels_up = path.count('../')\n",
        "        if levels_up > 0:\n",
        "            # Remove ../ parts and get the actual path (e.g., \"data/processed/train/images\")\n",
        "            actual_path = '/'.join(path.split('/')[levels_up:])\n",
        "            config['data_paths'][key] = str(project_root / actual_path)\n",
        "        else:\n",
        "            config['data_paths'][key] = str(project_root / path)\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(json.dumps(config, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Device and Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup device - check for CUDA, MPS (Apple Silicon), or CPU\n",
        "if torch.cuda.is_available() and config['model_settings']['device'] == 'cuda':\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using MPS (Apple Silicon GPU)\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU (no GPU acceleration available)\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Verify data paths exist\n",
        "print(\"\\nVerifying data paths:\")\n",
        "for split in ['train', 'val', 'test']:\n",
        "    img_path = Path(config['data_paths'][f'{split}_images'])\n",
        "    mask_path = Path(config['data_paths'][f'{split}_masks'])\n",
        "    img_exists = img_path.exists()\n",
        "    mask_exists = mask_path.exists()\n",
        "    img_count = len(list(img_path.glob('*.png'))) if img_exists else 0\n",
        "    mask_count = len(list(mask_path.glob('*.png'))) if mask_exists else 0\n",
        "    print(f\"  {split}: Images={img_count} ({'✓' if img_exists else '✗'}), Masks={mask_count} ({'✓' if mask_exists else '✗'})\")\n",
        "\n",
        "# Create data loaders\n",
        "print(\"\\nLoading datasets...\")\n",
        "train_loader, val_loader, test_loader = get_data_loaders(config)\n",
        "\n",
        "print(f\"\\nData loaders created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Validation batches: {len(val_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n",
        "\n",
        "# Check a sample batch\n",
        "sample_images, sample_masks = next(iter(train_loader))\n",
        "print(f\"\\nSample batch shape:\")\n",
        "print(f\"  Images: {sample_images.shape}\")\n",
        "print(f\"  Masks: {sample_masks.shape}\")\n",
        "print(f\"  Image value range: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
        "print(f\"  Mask value range: [{sample_masks.min():.3f}, {sample_masks.max():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create ResNet Encoder-Decoder Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ResNet encoder-decoder model\n",
        "model = create_resnet_model(config)\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model: {config['model2_resnet']['name']}\")\n",
        "print(f\"Backbone: {config['model2_resnet']['backbone']}\")\n",
        "print(f\"Decoder channels: {config['model2_resnet']['decoder_channels']}\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Test forward pass\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_output = model(sample_images[:2].to(device))\n",
        "    print(f\"\\nTest forward pass:\")\n",
        "    print(f\"  Input shape: {sample_images[:2].shape}\")\n",
        "    print(f\"  Output shape: {test_output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = ModelTrainer(\n",
        "    model=model,\n",
        "    config=config,\n",
        "    device=device,\n",
        "    model_name='resnet_model2'\n",
        ")\n",
        "\n",
        "# Train model\n",
        "num_epochs = config['model_settings']['num_epochs']\n",
        "trainer.train(\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=num_epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "checkpoint_path = method_root / 'outputs' / 'models' / 'resnet_model2_best.pth'\n",
        "if checkpoint_path.exists():\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
        "    print(f\"Best validation loss: {checkpoint['best_val_loss']:.4f}\")\n",
        "    print(f\"Best validation IoU: {checkpoint['best_val_iou']:.4f}\")\n",
        "else:\n",
        "    print(\"Best model checkpoint not found, using current model state\")\n",
        "\n",
        "# Create evaluator\n",
        "output_dir = method_root / config['output_paths']['predictions']\n",
        "results_dir = method_root / config['results_paths']['metrics']\n",
        "\n",
        "evaluator = ModelEvaluator(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    output_dir=output_dir,\n",
        "    results_dir=results_dir\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_metrics = evaluator.evaluate(\n",
        "    test_loader=test_loader,\n",
        "    save_predictions=config['evaluation']['save_predictions'],\n",
        "    num_visualizations=config['evaluation']['num_visualizations']\n",
        ")\n",
        "\n",
        "# Print metrics\n",
        "evaluator.print_metrics(test_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training History Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training history\n",
        "history_path = method_root / 'outputs' / 'models' / 'resnet_model2_history.json'\n",
        "if history_path.exists():\n",
        "    with open(history_path, 'r') as f:\n",
        "        history = json.load(f)\n",
        "    \n",
        "    # Plot training curves\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Loss plot\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Validation Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # IoU plot\n",
        "    axes[1].plot(history['train_iou'], label='Train IoU')\n",
        "    axes[1].plot(history['val_iou'], label='Validation IoU')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('IoU')\n",
        "    axes[1].set_title('Training and Validation IoU')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(method_root / 'outputs' / 'visualizations' / 'training_history_resnet.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Training completed in {len(history['train_loss'])} epochs\")\n",
        "else:\n",
        "    print(\"Training history not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "ResNet encoder-decoder model training and evaluation completed. Results saved to:\n",
        "- **Models**: `outputs/models/`\n",
        "- **Predictions**: `outputs/predictions/`\n",
        "- **Visualizations**: `outputs/visualizations/`\n",
        "- **Metrics**: `results/metrics/`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
